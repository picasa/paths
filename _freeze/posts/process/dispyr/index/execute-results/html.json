{
  "hash": "470c2aa0245b8ee998a0cfcccada0c8e",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Dispyr\"\nsubtitle: \"Processing topographical data into monochromatic ink sketches.\"\nauthor: \"Pierre Casadebaig\"\ndate: \"2022-11-25\"\nimage: \"img/preview.jpg\"\n\nformat:\n  html:\n    toc: true\n    toc-location: left\n    code-link: true\n    code-fold: show\n    fig-width: 4\n    fig-height: 3.5\n    fig-dpi: 150\n\nexecute: \n  warning: false\n  message: false\n  \nlightbox: true\n---\n\n\n\n> ### Processing topographical data into monochromatic ink sketches.\n\nThis work is an attempt to emulate etching drawings with code, by playing with noise and data removal to create a natural rendering of random fragments of the Pyrénées. \n\n::: {.gallery-grid .small}\n<div> ![](img/gallery/dispyr_09.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_100.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_102.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_104.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_125.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_127.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_145.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_173.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_197.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_199.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_228.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_241.jpg){.lightbox group=\"default\"} </div>\n::: \n\n::: {.asterism}\n&#8258;\n:::\n\n\n## Inspiration and aims\n\nI was searching for an hybrid between the simplicity and efficiency of a famous data visualization in [astronomy](https://blogs.scientificamerican.com/sa-visual/pop-culture-pulsar-origin-story-of-joy-division-s-unknown-pleasures-album-cover-video/) and the Meridian [series](https://opensea.io/collection/meridian-by-matt-deslauriers) by Matt Deslauriers. Moreover, to be able to use a pen-plotter to trace the images on paper, the algorithm should produce relatively long lines rather than the myriad of short segments that make Meridian appealing. \n\n::: {.gallery-flow .two} \n![](./img/pulses.jpg)\n\n![](./img/meridian_638.webp)\n:::\n\n> **left** : \"Successive pulses from the first pulsar discovered, CP 1919, are here superimposed vertically. The pulses occur every 1.337 seconds. They are caused by rapidly spinning neutron star.\" From The Cambridge Encyclopaedia of Astronomy.  \n> **right** : Meridian #638\n\n\nThis algorithm feeds on elevation data produced by public structures with different technologies (image analysis, topographical radar, or lidar) and made available for reuse. In this sense, it differs from generative art, where the code is self-sufficient to produce results (see [why-love-generative-art](https://www.artnome.com/news/2018/8/8/why-love-generative-art))\nThis short article explains the underlying logic and software code. A basic reproducible example is available [here](https://github.com/picasa/generative_examples/blob/8b7709023006dc2456af225bc4ea3393b4cfc5d7/R/gis_ridge.rmd#L23) to encourage creative experiments. \n\nI won't comment much on the choice of the R language and the code itself. It's just that I knew this language for work, and I was curious to see if i could reuse it for other projects. For me, the [functional](https://adv-r.hadley.nz/fp.html) programming paradigm makes sense to interact with code, moreover when working in interrupted streaks. The broad data [exploration](https://r4ds.had.co.nz/explore-intro.html) workflow resonate with my somewhat reductionist creative approach, especially how the tools for data visualization enable to focus on visual experiments rather code for graphics.\nI also went for the easy way, thanks to the creators of incredible libraries for (spatial) data processing and graphics. For this project I used {{[stars](https://r-spatial.github.io/stars/)}}, {{[dplyr](https://dplyr.tidyverse.org/)}}, and {{[ggplot2](https://ggplot2.tidyverse.org/)}}.\n\nThe algorithm is composed by three main functions, created to be used successively (with the R pipe function, [`|>`](https://r4ds.hadley.nz/workflow-pipes.html)). This article broadly illustrates the content of these functions.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nget_features_ridge(seed = 15) |> gen_dispyr(n_ridges = 800) |> plot_ridge()\n```\n:::\n\n\n1. `get_features_ridge()` is a function of a random seed, and is used to generate the main features of the output (e.g. the location, orientation, style)\n2. `gen_dispyr()` uses this set of features to download and process data from a digital elevation model (3D) into a set of lines (2D).\n3. `plot_ridge()` renders the processed data into a vector image.\n\n## Process \n\n### Features generation\n\nThe outputs have only two broad features: a random location in the Pyrénées mountain range and a rendering style, randomly chosen among four methods with a set of probabilities. Most of the visual variability in the outputs is driven by the choice of geographical location, it gives the series a strong link with the subject, but somehow limits the maximum number of obtainable iterations. \n\n#### Location\n\nTo get a random location in the Pyrénées mountain range, we first define a sampling region (a 20 km wide buffer around the French-Spain border), and use `sf::st_sample` to sample a location in this polygon. The code is simplified to sample a mysterious location in a polygon defined by the Andorra borders.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load a polygon of the Andorra borders\npolygon <- rnaturalearth::ne_countries(\n  country = c(\"andorra\"), scale = \"medium\", returnclass = \"sf\"\n  ) |> st_transform(2154)\n\n# get a sample in the defined polygon \ncoord <- st_sample(polygon, size = 1) |> st_as_sf()\n```\n:::\n\n\n::: {.column-margin}\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/plot_features-1.png){width=600}\n:::\n:::\n\n::: \n\n#### Rendering style\n\nThe overall rendering style is impacted by a dozen parameters in the code (e.g. line density, position of lines in the y-axis, amount and position of removed data). Rather than a free exploration of this parameter space, which could lead to heterogeneous outputs, I defined a limited number of fixed sets of parameters. I created four styles, and named them as weather conditions (clear, mist, snow, storm). \n\nTechnically nothing complicated, the `get_features_ridge()` function returns a list of features and associated parameters, later used for the data processing step. The parameters are presented at the moment they are used in the code.\n\n\n\n### Data processing\n\nThis stage uses the previous set of features to download and process data from a digital elevation model (3D) into a set of lines (2D), with distinct processing steps.\n\n#### Getting a realistic description of the landscape\n\n\nThis step start by actually retrieving the elevation data around the sampled location (a 2x2 km square for the illustration, 20x15 km normally). The [{{elevatr}}](https://github.com/jhollist/elevatr) R package makes this step a breeze, but the process is the same when using local high-resolution data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# get DEM data in a 2x2 km region around the sampled point\ndem <- elevatr::get_elev_raster(\n  coord, z = 11, expand = 1E3, clip = \"bbox\") \n\n# use a heatmap to glance at elevation data\nplot <- ggplot() +\n  geom_stars(data = st_as_stars(dem)) +\n  geom_sf(data = coord, color = \"white\", size = 1) +\n  scale_fill_viridis_c(name = \"elevation\") +\n  labs(x = \"lon\", y = \"lat\") \n```\n:::\n\n\n\n::: {.column-margin}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/plot_sampling-1.png){width=600}\n:::\n:::\n\n:::\n\n\n\n#### Slicing the landscape into lines\n\nThe aim is to process a 3D point set into 2D lines, by computing multiple lines of elevation as a function of longitude, for discrete latitude values. \nThis step is perfectly illustrated by the stacked plot of radio signals presented previously. In our case, each line corresponds to one row in the elevation data (74x74 matrix in the example). Without further modifications, the output is unclear, with a lot of intersecting lines (figure A).\n\nTo improve the output readability, but also introduce potential for variations, we process this raw elevation matrix with two actions:\n\n  * shift lines in the y-direction as a function of their rank from the foreground.\n  * delete the line segments that should be hidden by foreground lines with a higher elevation. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# parameters\nz_shift = 5\n\n# convert DEM from spatial to dataframe format\ndf_dem <- dem |> stars::st_as_stars() |>\n  as_tibble() |> select(x, y, z = 3)  \n\n# compute elevation shift as a function of normalized distance\ndata_index <- df_dem |>\n  distinct(y) |> arrange(y) |>\n  mutate(\n    y_rank = rank(y),\n    y_dist = scales::rescale(y, to = c(0,1)),\n  ) |>\n  mutate(dz = y_rank * z_shift)\n\n# compute shifted elevation values\ndf_shift <- df_dem |> \n  left_join(data_index, by = \"y\") |>\n  group_by(y) |> mutate(xn = x - min(x), x_rank = rank(x)) |> ungroup() |>\n  mutate(zs = z + dz)\n```\n:::\n\n\n::: {.column-margin}\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/plot_shift-1.png){width=600}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_shift-2.png){width=600}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_shift-3.png){width=600}\n:::\n:::\n\n:::\n\nThe shifting step calculates the difference from the reference elevation as a linear function of its rank from the foreground (figure B). Increasing the slope of this function impacts the perspective, towards a more aerial view of the landscape, eventually reducing the number of intersecting lines (figure C). Using non-linear functions creates unrealistic but interesting perspectives. \n\nAt this step, a fast solution to achieve line intersection is by drawing lines with a filled area underneath, starting from the background and thus progressively masking previous polygons (as in painter's algorithm). This solution is implemented directly in the [ggridges](https://github.com/wilkelab/ggridges) R package. But this option is not ideal for creative coding : the hidden lines still exist, which makes vector outputs unusable with a pen-plotter, and it lacks flexibility on the overlaying method.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# parameters\nn_lag = 100\nz_threshold = 0\n\n# define window functions for multiple lag positions\nlist_distance <- map(glue::glue(\"~ . - lag(., n = {1:n_lag})\"), ~ as.formula(.))\nlist_col <- glue::glue(\"zs_{1:n_lag}\")\n\n# remove points hidden by foreground ridges :\n# compute lagged elevation difference between successive y for each x \n# replace value by NA when the difference is less than a threshold \ndf_ridge <- df_shift |> \n  arrange(y_rank) |> group_by(x) |>\n  mutate(across(zs, .fns = list_distance)) |>\n  ungroup() |> \n  mutate(\n    zn = case_when(\n      if_any(all_of(list_col), ~ . < z_threshold) ~ NA_real_,\n      TRUE ~ zs)) |>\n  select(- all_of(list_col))\n```\n:::\n\n\n\nIn the code above, the intersections between lines are avoided by checking for a minimum distance between a point at a given *x* position and its neighbourhood along *y*, and removing the point if any points in the neighbourhood falls below this distance (*z_threshold* parameter). To avoid computing the distance matrix for all points (74^4^, in this small area), we only check for intersections along a limited range (*n_lag* parameter, between 0 and 300 y ranks). Increasing the threshold parameter creates clearer distinction between the sides of mountains.  \n\n\n\n::: {.cell .column-body layout-ncol=\"3\"}\n::: {.cell-output-display}\n![](index_files/figure-html/plot_intersect-1.png){width=450}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_intersect-2.png){width=450}\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/plot_intersect-3.png){width=450}\n:::\n:::\n\n\n> Line segments are hidden by foreground lines by using polygon masking (left) or distance-based point removal with a null (center) or positive threshold (right).\n\n\n::: {.cell}\n\n:::\n\n\n![](img/fig_intersection.png)\n\n> Effect of *shift* (in rows) and *threshold* (in columns) parameter combination on the landscape rendering (16 km^2^).\n\n#### Altering the lines with noise and deletion\n\nFinally, the overall aesthetic is obtained by adding noise and discarding data as a function of various attributes (elevation, slope, elevation dispersion). The governing idea was to test how our perception of the landscape changes when most of the initial topographical data is perturbed or removed. Here are four methods, but much is left to explore. The illustration code here is functioning without external call, but highly redundant and surely not optimal, you can conveniently hide it if you feel horrified.\n\n\n::: {.cell}\n\n:::\n\n\n![](img/fig_styles.png)\n\n> Four data processing methods, all based on filtering points and adding noise, and named after weather conditions (clear, mist, snow, storm).\n\n##### *clear*\nFor each ridgeline, the method samples 50 % of the points and adds moderate jitter on elevation values.\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n# parameters\nz_remove = 0.5      # proportion of points to remove\nz_jitter = 4        # amount of jitter in elevation values\n\n# randomly sample a proportion of points in a line, jitter their y-position.\ndf_plot <- df_ridge |>\n  group_by(y_rank) |>\n  slice_sample(prop = (1 - z_remove)) |>\n  mutate(zn = jitter(zn, amount = z_jitter))\n\n# plot output\ndf_plot |> ggplot(aes(x, zn, group = y)) +\n  geom_line(alpha = 0.5) + coord_fixed() + theme_void() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/code_clear-1.png){width=600}\n:::\n:::\n\n\n##### *mist*\nSame base as the previous method. In addition, when below an elevation threshold, lines are smoothed and points are randomly removed.\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n# functions\n\n# add a proportion of missing values in a vector\nsample_missing <- function(x, p) {\n  n <- length(x)\n  s <- sample(1:n, size = p * n)\n  x[s] <- NA\n  return(x)\n}\n\n# parameters\nx_size = 10         # window of the rolling average \nz_limit = 0.5       # quantile value determining the elevation threshold\nz_remove = 0.5      # proportion of points to remove in lines\nz_missing = 0.2     # proportion of missing value to add\nz_jitter = 4        # amount of jitter in elevation values\n\n# calculate elevation cut\nz_cut = quantile(df_ridge$z, z_limit, na.rm = TRUE)\n\n# smooth lines with a rolling mean \ndf_smooth <- df_ridge |>\n  group_by(y_rank) |>\n  mutate(\n    zm = RcppRoll::roll_mean(zn, n = x_size, fill = NA),\n    zm = case_when(\n      (is.na(zm) & (x_rank < x_size/2 | x_rank > max(x_rank) - x_size/2)) ~ zn,\n      TRUE ~ zm)) \n\n# remove data as a function of elevation, jitter y-position above a threshold   \ndf_plot <- df_smooth |> \n  slice_sample(prop = (1 - z_remove)) |>\n  mutate(\n    zn = case_when(\n      (z < (z_cut - 200)) ~ sample_missing(zm, p = z_missing + 0.2),\n      (z < z_cut)         ~ sample_missing(zm, p = z_missing),\n      TRUE                ~ zn),\n    zn = if_else(z > z_cut, jitter(zn, amount = z_jitter), zn)\n  ) \n\n# plot output\ndf_plot |> ggplot(aes(x, zn, group = y)) +\n  geom_line(alpha = 0.5) + coord_fixed() + theme_void() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/code_mist-1.png){width=600}\n:::\n:::\n\n\n##### *snow*\nSame base as the previous method, but the data removal is also a function of a slope threshold.\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n# parameters\nx_size = 5          # window of the rolling average \nz_limit = 0.7       # quantile value determining the elevation threshold\nz_remove = 0.5      # proportion of points to remove in lines\nz_missing = 0.6     # proportion of missing value to add\nz_jitter = 4        # amount of jitter in elevation values\n\n# calculate elevation cut\nz_cut = quantile(df_ridge$z, z_limit, na.rm = TRUE)\n\n# calculate local slope and remove points for flat areas\ndf_filter <- df_ridge |>\n    group_by(y_rank) |> arrange(x_rank) |>\n    mutate(\n      z_slope = abs(\n        (zn - lag(zn, default = 0)) / (xn - lag(xn, default = 0))\n        ),\n      z_slope = RcppRoll::roll_mean(z_slope, n = x_size, fill = NA_real_),\n      zn = if_else(z_slope == 0, NA_real_, zn)\n    ) |> ungroup()\n\n# remove data as a function of slope and elevation   \ndf_plot <- df_filter |>\n  group_by(y_rank) |>\n  slice_sample(prop = (1 - z_remove)) |>\n  mutate(\n    zn = case_when(\n      (z > z_cut) & (z_slope < 60/100)         ~\n        sample_missing(zn, p = z_missing),\n      (z > (z_cut - 100)) & (z_slope < 60/100) ~\n        sample_missing(zn, p = z_missing / 2),\n      TRUE                                     ~\n        zn),\n    zn = jitter(zn, amount = z_jitter)\n  ) \n\n# plot output\ndf_plot |> ggplot(aes(x, zn, group = y)) +\n  geom_line(alpha = 0.5) + coord_fixed() + theme_void() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/code_snow-1.png){width=600}\n:::\n:::\n\n\n##### *storm*\nWhole strips of lines are removed when the elevation variation is below a threshold. Additionally, an important jitter is added as a function of local slope value.\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code  code-fold=\"true\"}\n# functions\n\n# scale the input vector with an exponential function\nf_exp <- function(x, k = 1, a = 1, b = 0, scale = FALSE) {\n  if (scale == TRUE) x = scales::rescale(x, to=c(0,1)) else x\n  a * exp(k * x) + b\n}\n\n# find multiple non-consecutive minima in a vector (this is awful) \nget_extremum <- function(data, n = 5, w = 20, delta = 20, method = \"max\") {\n  data |>\n    mutate(\n      y_smooth = RcppRoll::roll_mean(y_raw, n = w, na.rm = TRUE, fill = NA)\n    ) |>\n    filter((y_smooth - y_raw) > delta) |>\n    filter(\n      if_else(\n        lag(y_raw, n = 1) > y_raw & lead(y_raw, n = 1) > y_raw,\n        TRUE, FALSE)\n    ) |>\n    slice_min(y_raw, n = n)\n}\n\n# parameters\ny_range = 5        # number of ridges to remove around selected ones\nx_size = 5          # window of the rolling average \nz_remove = 0.5      # proportion of points to remove in lines\nz_jitter = 4        # amount of jitter in elevation values\n\n\n# get maximum number of ridgelines\nn_ridge_max <- df_ridge |> distinct(y_rank) |> nrow()\n\n# calculate local slope and remove points for flat areas\ndf_filter <- df_ridge |>\n    group_by(y_rank) |> arrange(x_rank) |>\n    mutate(\n      z_slope = abs(\n        (zn - lag(zn, default = 0)) / (xn - lag(xn, default = 0))\n        ),\n      z_slope = RcppRoll::roll_mean(z_slope, n = x_size, fill = NA_real_),\n      zn = if_else(z_slope == 0, NA_real_, zn)\n    ) |> ungroup()\n\n# compute potential distortion on z-axis as a function of local slope on x-axis\n# jitter by sampling in this distortion level for each point\ndf_sample <- df_filter |>\n  group_by(y_rank) |>\n  slice_sample(prop = (1 - z_remove)) |>\n  mutate(z_jitter = f_exp(z_slope, k = 3.5, a = 0.3, scale = TRUE) * z_jitter) |>\n  ungroup() |>\n  mutate(\n    z_jitter = runif(n(), -z_jitter, z_jitter),\n    zn = zn + z_jitter\n  )\n\n# get ridges position with low elevation variance\nindex_strip <- df_sample |>\n  group_by(y_rank) |>\n  summarise(y_raw = sd(z, na.rm = TRUE)) |>\n  get_extremum(n = as.integer(z_remove * 5), w = 30, delta = 3, method = \"min\") |>\n  filter(between(y_rank, (y_range + 5), (n_ridge_max - y_range - 5)))\n\n# remove strips of ridges based on previous index\ndf_plot <- anti_join(\n  df_sample,\n  df_sample |>\n    distinct(y_rank) |>\n    slice(\n      index_strip |> pull(y_rank) |>\n        map(~ (.x - y_range):(.x + y_range)) |>\n        flatten_int()\n    ),\n  by = \"y_rank\"\n)\n\n# plot output\ndf_plot |> ggplot(aes(x, zn, group = y)) +\n  geom_line(alpha = 0.5) + coord_fixed() + theme_void() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/code_storm-1.png){width=600}\n:::\n:::\n\n\n\n### Rendering\n\nThis step is essentially playing on opacity (either constant or variable along a line) and on the doubling of the line strokes to emulate pencil lines. Thanks to the R graphical devices, the same object can be exported to bitmap or vector files.\n\n#### *default*\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n# parameters\nz_remove = 0.5      # proportion of points to remove\nz_jitter = 4        # amount of jitter in elevation values\np_alpha = 0.5       # mean opacity value\n\n# randomly sample a proportion of points in a line, jitter their y-position.\ndf_plot <- df_ridge |>\n  group_by(y_rank) |>\n  slice_sample(prop = (1 - z_remove)) |>\n  mutate(zn = jitter(zn, amount = z_jitter))\n\n# render lines with a constant alpha value\ndf_plot |> ggplot(aes(x, zn, group = y)) +\n  geom_line(alpha = p_alpha) + coord_fixed() + theme_void() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/code_plain-1.png){width=600}\n:::\n:::\n\n\n#### *variable opacity*\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n# parameters\np_alpha_sd = 0.10   # dispersion of opacity value \n\n# render line with an alpha value sampled from a Gaussian distribution\ndf_plot |>\n  mutate(z_alpha = rnorm(n(), p_alpha, p_alpha_sd)) |> \n  ggplot(aes(x, zn)) +\n  geom_line(aes(group = y_rank, alpha = z_alpha)) +\n  scale_alpha_identity() + coord_fixed() + theme_void() \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/code_pencil-1.png){width=600}\n:::\n:::\n\n\n#### *variable opacity and double strokes*\n\n\n::: {.cell .column-margin}\n\n```{.r .cell-code}\n# functions\n# fit a polynomial determined by one or more numerical predictors\nf_loess <- function(data, span, n = 10) {\n\n  # do not fit model if less than n non-na values\n  if (sum(!is.na(data$zn)) < n) {\n\n    return(rep(NA, nrow(data)))\n\n  } else {\n\n    m <- loess(zn ~ xn, data = data, na.action = na.exclude, span = span)\n    return(predict(m))\n\n  }\n}\n\n# parameters\np_span = 0.5      # span of the smoothing model (smaller fits the line)\np_length = 25     # minimal line length to apply the smoothing model\n\n# render line with two strokes, and variable alpha\ndf_smooth <- df_plot |>\n  group_by(y_rank) |> nest() |>\n  mutate(z_smooth = map(data, ~ f_loess(., span = p_span, n = p_length))) |>\n  unnest(c(data, z_smooth))\n\nggplot() +\n  geom_line(\n    data = df_plot |> mutate(z_alpha = rnorm(n(), p_alpha, p_alpha_sd)),\n    aes(xn, zn, group = y_rank, alpha = z_alpha), na.rm = TRUE) +\n  geom_line(\n    data = df_smooth,\n    aes(xn, z_smooth, group = y_rank), alpha = p_alpha) +\n  scale_alpha_identity() + coord_fixed() + theme_void()\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/code_stroke-1.png){width=600}\n:::\n:::\n\n\n## Iterations\n\nThese outputs were generated with the algorithm described previously, but based on a random location in the whole Pyrenees range (with a larger geographical area - 15x20 km, and a random cardinal orientation), and a random aesthetic style among the four presented ones. The algorithm can handle about 1000 iterations before repeating information (about 70 distinct 300 km2 regions with limited overlapping, 4 orientations, and 4 styles).\n\n> An example of 32 random iterations from this algorithm.\n\n::: {.column-screen-inset .gallery-grid .small}\n<div> ![](img/gallery/dispyr_09.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_100.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_102.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_104.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_125.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_127.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_145.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_173.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_197.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_199.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_228.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_241.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_266.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_312.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_316.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_320.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_354.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_359.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_377.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_398.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_402.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_434.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_436.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_438.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_456.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_47.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_475.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_480.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_488.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_56.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_62.jpg){.lightbox group=\"default\"} </div>\n<div> ![](img/gallery/dispyr_69.jpg){.lightbox group=\"default\"} </div>\n::: \n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}